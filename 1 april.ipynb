{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40cb408-209d-4993-9f31-0d9e7b6f9001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Differences between Linear Regression and Logistic Regression:\\n   Linear Regression is used to handle regression problems \\n   Linear regression provides a continuous output\\n    example: if an individual was 70 inches tall, we would predict his weight to be: Weight = 80 + 2 x (70) = 220 lbs.\\n    In this simple linear regression, we are examining the impact of one independent variable on the outcome\\n   \\n   Logistic regression is used to handle the classification problems\\n   Logistic regression provides discreet output\\n    example: a logistic regression could be used to predict whether a political candidate will win or lose an election\\n    or whether a high school student will be admitted or not to a particular college. These binary outcomes allow\\n    straightforward decisions between two alternatives.\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''The Differences between Linear Regression and Logistic Regression:\n",
    "   Linear Regression is used to handle regression problems \n",
    "   Linear regression provides a continuous output\n",
    "    example: if an individual was 70 inches tall, we would predict his weight to be: Weight = 80 + 2 x (70) = 220 lbs.\n",
    "    In this simple linear regression, we are examining the impact of one independent variable on the outcome\n",
    "   \n",
    "   Logistic regression is used to handle the classification problems\n",
    "   Logistic regression provides discreet output\n",
    "    example: a logistic regression could be used to predict whether a political candidate will win or lose an election\n",
    "    or whether a high school student will be admitted or not to a particular college. These binary outcomes allow\n",
    "    straightforward decisions between two alternatives.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1aa882-e365-4600-8cfa-acb3a30f27a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cost function used in Logistic Regression is Log Loss.\\n   The cost function of logistic regression is derived from taking the log of the maximum likelihood function and\\n   applying negative to log loss function in order to use gradient descent for optimization purposes. This is why the \\n   cross-entropy loss function is also called a log loss function.\\n    cost function optimized:\\n    A Cost function is used to gauge the performance of the Machine Learning model. A Machine Learning model devoid of\\n    the Cost function is futile. Cost Function helps to analyze how well a Machine Learning model performs. A Cost\\n    function basically compares the predicted values with the actual values.\\n    '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''The cost function used in Logistic Regression is Log Loss.\n",
    "   The cost function of logistic regression is derived from taking the log of the maximum likelihood function and\n",
    "   applying negative to log loss function in order to use gradient descent for optimization purposes. This is why the \n",
    "   cross-entropy loss function is also called a log loss function.\n",
    "    cost function optimized:\n",
    "    A Cost function is used to gauge the performance of the Machine Learning model. A Machine Learning model devoid of\n",
    "    the Cost function is futile. Cost Function helps to analyze how well a Machine Learning model performs. A Cost\n",
    "    function basically compares the predicted values with the actual values.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf78c60-20b0-454c-8183-8f9afbd5f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regularization for logistic regression\\n   Regularization is used to reduce the complexity of the prediction function by imposing a penalty. In the case of the \\n   linear relationship, regularization adds the following term to the cost fuction: where D is the dimension of features.\\n\\n   Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization \\n   error but not its training error. In other words: regularization can be used to train models that generalize better\\n   on unseen data, by preventing the algorithm from overfitting the training dataset.\\n   \\n   In an overfit model, the coefficients are generally inflated. Thus, Regularization adds penalties to the parameters \\n   and avoids them weigh heavily. The coefficients are added to the cost function of the linear equation. Thus, if the \\n   coefficient inflates, the cost function will increase.\\n   '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''Regularization for logistic regression\n",
    "   Regularization is used to reduce the complexity of the prediction function by imposing a penalty. In the case of the \n",
    "   linear relationship, regularization adds the following term to the cost fuction: where D is the dimension of features.\n",
    "\n",
    "   Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization \n",
    "   error but not its training error. In other words: regularization can be used to train models that generalize better\n",
    "   on unseen data, by preventing the algorithm from overfitting the training dataset.\n",
    "   \n",
    "   In an overfit model, the coefficients are generally inflated. Thus, Regularization adds penalties to the parameters \n",
    "   and avoids them weigh heavily. The coefficients are added to the cost function of the linear equation. Thus, if the \n",
    "   coefficient inflates, the cost function will increase.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c0589c-2b13-4c42-8f6e-7ed6b25e6e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC curves in logistic regression\\n        are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or\\n        a \"success\" (1). If you\\'re not familiar with ROC curves, they can take some effort to understand. \\n        example:  ROC curve from logistic regression is shown below.\\n   \\n   The Area Under the ROC curve (AUC) is an aggregated metric that evaluates how well a logistic regression model\\n   classifies positive and negative outcomes at all possible cutoffs. It can range from 0.5 to 1, and the larger it is\\n   the better.\\n   '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''ROC curves in logistic regression\n",
    "        are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or\n",
    "        a \"success\" (1). If you're not familiar with ROC curves, they can take some effort to understand. \n",
    "        example:  ROC curve from logistic regression is shown below.\n",
    "   \n",
    "   The Area Under the ROC curve (AUC) is an aggregated metric that evaluates how well a logistic regression model\n",
    "   classifies positive and negative outcomes at all possible cutoffs. It can range from 0.5 to 1, and the larger it is\n",
    "   the better.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16520992-5648-47a4-b644-39f5cde3a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are several types of statistical tests that can be used for filter feature selection, including chi-square, \\n   ANOVA, and mutual information. These tests measure the degree of association between the features and the target  \\n   variable, and can help identify the most relevant features for the model.\\n \\n evaluation of a model using all input features\\nfrom sklearn.datasets import make_regression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_absolute_error\\n# load the dataset\\nX, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\\n# split into train and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\\n# fit the model\\nmodel = LinearRegression()\\nmodel.fit(X_train, y_train)\\n# evaluate the model\\nyhat = model.predict(X_test)\\n# evaluate predictions\\nmae = mean_absolute_error(y_test, yhat)\\nprint('MAE: %.3f' % mae)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''There are several types of statistical tests that can be used for filter feature selection, including chi-square, \n",
    "   ANOVA, and mutual information. These tests measure the degree of association between the features and the target  \n",
    "   variable, and can help identify the most relevant features for the model.\n",
    " \n",
    " evaluation of a model using all input features\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53ee81d-214d-44dc-90ed-7a7889d98de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' handle imbalanced datasets in logistic regression:\\n1. 7 Techniques to Handle Imbalanced Data. \\n2. Use the right evaluation metrics. \\n3. Resample the training set. \\n4. Use K-fold Cross-Validation in the Right Way. \\n5. Ensemble Different Resampled Datasets.\\n6. Resample with Different Ratios.\\n7. Cluster the abundant class. \\n8. Design Your Models.\\n\\nIn logistic regression, another technique comes handy to work with imbalance distribution. This is to use class-weights\\nin accordance with the class distribution. Class-weights is the extent to which the algorithm is punished for any wrong\\nprediction of that class.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "''' handle imbalanced datasets in logistic regression:\n",
    "1. 7 Techniques to Handle Imbalanced Data. \n",
    "2. Use the right evaluation metrics. \n",
    "3. Resample the training set. \n",
    "4. Use K-fold Cross-Validation in the Right Way. \n",
    "5. Ensemble Different Resampled Datasets.\n",
    "6. Resample with Different Ratios.\n",
    "7. Cluster the abundant class. \n",
    "8. Design Your Models.\n",
    "\n",
    "In logistic regression, another technique comes handy to work with imbalance distribution. This is to use class-weights\n",
    "in accordance with the class distribution. Class-weights is the extent to which the algorithm is punished for any wrong\n",
    "prediction of that class.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adee29-e1ea-4423-b15e-9efb01bcee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7\n",
    "'''problem facing while use of logistic regression:\n",
    "   Logistic regression is an example of supervised learning. It is used to calculate or predict the probability of a\n",
    "   binary (yes/no) event occurring. An example of logistic regression could be applying machine learning to determine\n",
    "   if a person is likely to be infected with COVID-19 or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
